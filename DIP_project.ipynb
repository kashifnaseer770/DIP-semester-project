{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad48ca2-8c7b-42db-b3a9-97e49135f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc23e74-55c4-49c8-9a86-b9dfabd7a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "def unzip_files():\n",
    "    for zip_file in ['male1.zip', 'female.zip']:\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall()\n",
    "\n",
    "def augment_image(image):\n",
    "    # Flip horizontally\n",
    "    flipped = cv2.flip(image, 1)\n",
    "    # Rotate 90 degrees\n",
    "    rotated = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    # Random brightness and contrast\n",
    "    alpha = 0.8 + random.uniform(0, 0.4)  # Contrast control (0.8-1.2)\n",
    "    beta = random.randint(-20, 20)  # Brightness control\n",
    "    adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return [image, flipped, rotated, adjusted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2ac4a-eb7a-4a9b-931e-9b5f3a1fce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1119s\u001b[0m 16s/step\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2183s\u001b[0m 30s/step\n",
      "Accuracy: 0.8476 ± 0.0188\n",
      "Precision: 0.8536 ± 0.0236\n",
      "Recall: 0.8373 ± 0.0327\n",
      "F1-Score: 0.8450 ± 0.0226\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))  # Resize for VGG19\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Histogram equalization\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    # Contrast normalization\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # Convert back to color for VGG19\n",
    "    image = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    image = preprocess_input(image)  # For VGG19\n",
    "    return image, gray\n",
    "\n",
    "def load_data():\n",
    "    images, grays, labels = [], [], []\n",
    "    # Count original images in each folder\n",
    "    male_count = len([f for f in os.listdir('male1') if f.endswith(('.jpg', '.png'))])\n",
    "    female_count = len([f for f in os.listdir('female') if f.endswith(('.jpg', '.png'))])\n",
    "    max_samples = min(male_count, female_count) * 4  # Max samples after augmentation (4 per image)\n",
    "\n",
    "    for folder, label in [('male1', 0), ('female', 1)]:\n",
    "        sample_count = 0\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                if sample_count >= max_samples // 4:  # Limit to max original images\n",
    "                    break\n",
    "                img_path = os.path.join(folder, filename)\n",
    "                image, gray = preprocess_image(img_path)\n",
    "                # Augment images\n",
    "                augmented_images = augment_image(image)\n",
    "                augmented_grays = augment_image(gray)\n",
    "                images.extend(augmented_images)\n",
    "                grays.extend(augmented_grays)\n",
    "                labels.extend([label] * len(augmented_images))\n",
    "                sample_count += 1\n",
    "    return np.array(images), np.array(grays), np.array(labels)\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "def extract_hog_features(gray_images):\n",
    "    hog_features = []\n",
    "    for gray in gray_images:\n",
    "        features, hog_image = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features), hog_image\n",
    "\n",
    "def extract_lbp_features(gray_images):\n",
    "    lbp_features = []\n",
    "    lbp_image = None\n",
    "    for i, gray in enumerate(gray_images):\n",
    "        lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)\n",
    "        lbp_features.append(hist)\n",
    "        if i == 0:  # Save the first LBP for visualization\n",
    "            lbp_image = lbp\n",
    "    return np.array(lbp_features), lbp_image\n",
    "\n",
    "def extract_glcm_features(gray_images):\n",
    "    glcm_features = []\n",
    "    glcm_sample = None\n",
    "    for i, gray in enumerate(gray_images):\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        glcm_features.append([contrast, dissimilarity, homogeneity])\n",
    "        if i == 0:  # Save the first GLCM features for visualization\n",
    "            glcm_sample = [contrast, dissimilarity, homogeneity]\n",
    "    return np.array(glcm_features), glcm_sample\n",
    "\n",
    "def visualize_features(hog_image, lbp_image, glcm_sample):\n",
    "    # Visualize HOG\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.title('HOG Visualization')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('hog_visualization.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Visualize LBP\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(lbp_image, cmap='gray')\n",
    "    plt.title('LBP Visualization')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('lbp_visualization.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Visualize GLCM features as a bar chart\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    glcm_labels = ['Contrast', 'Dissimilarity', 'Homogeneity']\n",
    "    plt.bar(glcm_labels, glcm_sample, color='skyblue')\n",
    "    plt.title('GLCM Features Visualization')\n",
    "    plt.ylabel('Value')\n",
    "    plt.savefig('glcm_visualization.png')\n",
    "    plt.close()\n",
    "\n",
    "def extract_vgg19_features(images):\n",
    "    # Load VGG19 with fully connected layers (include_top=True)\n",
    "    model = VGG19(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "    # Create models for fc2 and predictions layers\n",
    "    fc2_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
    "    pred_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('predictions').output)\n",
    "    fc2_features = fc2_model.predict(images, batch_size=32)# Extract features\n",
    "    pred_features = pred_model.predict(images, batch_size=32)\n",
    "    vgg_features = np.concatenate((fc2_features, pred_features), axis=1) # Concatenate features\n",
    "    return vgg_features\n",
    "\n",
    "# Step 3: Feature Fusion and Dimensionality Reduction\n",
    "def feature_fusion(hog, lbp, glcm, vgg19):\n",
    "    # Serial-based fusion\n",
    "    low_level = np.hstack((hog, lbp, glcm))\n",
    "    fused = np.hstack((low_level, vgg19))\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    fused = scaler.fit_transform(fused)\n",
    "    # PCA\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "    fused_reduced = pca.fit_transform(fused)\n",
    "    # Visualize PCA explained variance\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_, color='skyblue')\n",
    "    plt.title('PCA Explained Variance Ratio')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.savefig('pca_variance.png')\n",
    "    plt.close()\n",
    "    return fused_reduced\n",
    "\n",
    "# Step 4 & 5: Classification and Evaluation\n",
    "def classify_and_evaluate(features, labels):\n",
    "    # Use class_weight='balanced' to handle class imbalance\n",
    "    svm = LinearSVC(max_iter=10000, class_weight='balanced')\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "    all_y_true, all_y_pred = [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(features):\n",
    "        X_train, X_test = features[train_idx], features[test_idx]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='binary'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='binary'))\n",
    "        f1s.append(f1_score(y_test, y_pred, average='binary'))\n",
    "\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "    print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n",
    "    print(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n",
    "    print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Unzip files\n",
    "    unzip_files()\n",
    "\n",
    "    # Load and preprocess data\n",
    "    images, grays, labels = load_data()\n",
    "\n",
    "    # Extract features and get visualizations for the first image\n",
    "    hog_features, hog_image = extract_hog_features(grays)\n",
    "    lbp_features, lbp_image = extract_lbp_features(grays)\n",
    "    glcm_features, glcm_sample = extract_glcm_features(grays)\n",
    "    vgg19_features = extract_vgg19_features(images)\n",
    "\n",
    "    # Visualize HOG, LBP, and GLCM for the first image\n",
    "    visualize_features(hog_image, lbp_image, glcm_sample)\n",
    "\n",
    "    # Feature fusion and dimensionality reduction\n",
    "    fused_features = feature_fusion(hog_features, lbp_features, glcm_features, vgg19_features)\n",
    "\n",
    "    # Classify and evaluate\n",
    "    classify_and_evaluate(fused_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30af8eb-4b36-4d45-8759-a24b547ec499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
